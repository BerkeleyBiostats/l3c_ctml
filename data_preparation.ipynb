{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seraphinashi/Desktop/l3c_ctml'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify we're in the correct working directory\n",
    "import os\n",
    "os.getcwd()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.STEP1_feature import a_cohort as a\n",
    "from src.STEP1_feature import b_medication as b\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 15:19:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "synthetic_data/training/observation_period.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data/training/drug_exposure.csv\n",
      "synthetic_data/training/death.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data/training/measurement.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data/training/condition_occurrence.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data/training/microvisits_to_macrovisits.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data/training/visit_occurrence.csv\n",
      "synthetic_data/training/long_covid_silver_standard.csv\n",
      "synthetic_data/training/person.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data/training/observation.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data/training/procedure_occurrence.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"l3c_ctml\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Read CSV file into table\n",
    "data_path = \"synthetic_data/training\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('table', StringType(), True),\n",
    "    StructField('field', StringType(), True),\n",
    "    StructField('type', StringType(), True)\n",
    "])\n",
    "\n",
    "all_fields = spark.createDataFrame([], schema)\n",
    "    \n",
    "for path, subdirs, files in os.walk(data_path):\n",
    "    for name in files:\n",
    "        if \"csv\" in name and name[0]!=\".\":\n",
    "            # table_fields = [(table_name, f.name, str(f.dataType)) for f in datafile.schema.fields]\n",
    "            full_file = (os.path.join(path, name))\n",
    "            df = spark.read.csv(os.path.join(path, name), header=True, inferSchema=True)\n",
    "            var_name = name[:-4]\n",
    "            print(full_file)\n",
    "            globals()[var_name] = df\n",
    "\n",
    "concept = spark.read.csv(\"synthetic_data/concept.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1_cohort_and_features\n",
    "\n",
    "covid_pasc_index_dates = a.sql_statement_01(long_covid_silver_standard)\n",
    "cohort = a.sql_statement_00(covid_pasc_index_dates, person)\n",
    "long_covid_patients = a.sql_statement_08(covid_pasc_index_dates)\n",
    "\n",
    "hosp_cases = a.sql_statement_04(cohort, condition_occurrence, microvisits_to_macrovisits)\n",
    "\n",
    "hosp_and_non = a.sql_statement_06(cohort, hosp_cases)\n",
    "\n",
    "Feature_Table_Builder_v0 = a.sql_statement_03(covid_pasc_index_dates, hosp_and_non, microvisits_to_macrovisits)\n",
    "# ICU_visits = a.sql_statement_05(microvisits_to_macrovisits)\n",
    "# inpatient_visits = spark.sql(sql_statement_07())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2_med_feature_table\n",
    "DrugConcepts = b.sql_statement_00(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'drug_exposure.*' given input columns 'person_id, drug_exposure_start_date, refills, drug_source_value, drug_exposure_end_date, route_concept_id, quantity, lot_number, days_supply, sig, drug_type_concept_id, drug_source_concept_id, provider_id, route_source_value, drug_exposure_id, dose_unit_source_value, drug_exposure_start_datetime, drug_exposure_end_datetime, visit_detail_id, verbatim_end_date, stop_reason, drug_concept_id, visit_occurrence_id, person_id, patient_group, apprx_age, sex, race, ethn, min_covid_dt_2, tot_long_data_days, pre_pre_window_start_dt, pre_window_start_dt, pre_window_end_dt, post_window_start_dt, post_window_end_dt, post_visits_count, tot_post_days, tot_covid_days, op_post_visit_ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     selected_df \u001b[38;5;241m=\u001b[39m joined_df\u001b[38;5;241m.\u001b[39mselect(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrug_exposure.*\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(selected_df)\n\u001b[0;32m---> 11\u001b[0m Drugs_for_These_Patients \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFeature_Table_Builder_v0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrug_exposure\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m, in \u001b[0;36mexp\u001b[0;34m(Feature_table_builder, drug_exposure)\u001b[0m\n\u001b[1;32m      5\u001b[0m joined_df \u001b[38;5;241m=\u001b[39m drug_exposure\u001b[38;5;241m.\u001b[39mjoin(Feature_table_builder, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Select all columns from drug_exposure DataFrame\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m selected_df \u001b[38;5;241m=\u001b[39m \u001b[43mjoined_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrug_exposure.*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(selected_df)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/dataframe.py:2023\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/dataframe.py?line=2001'>2002</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcols: \u001b[39m\"\u001b[39m\u001b[39mColumnOrName\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/dataframe.py?line=2002'>2003</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/dataframe.py?line=2003'>2004</a>\u001b[0m \n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/dataframe.py?line=2004'>2005</a>\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/dataframe.py?line=2020'>2021</a>\u001b[0m \u001b[39m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/dataframe.py?line=2021'>2022</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/dataframe.py?line=2022'>2023</a>\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mselect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jcols(\u001b[39m*\u001b[39;49mcols))\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/dataframe.py?line=2023'>2024</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py?line=1314'>1315</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py?line=1315'>1316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py?line=1316'>1317</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py?line=1317'>1318</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py?line=1319'>1320</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> <a href='file:///~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py?line=1320'>1321</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py?line=1321'>1322</a>\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py?line=1323'>1324</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   <a href='file:///~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py?line=1324'>1325</a>\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/utils.py?line=191'>192</a>\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/utils.py?line=192'>193</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/utils.py?line=193'>194</a>\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/utils.py?line=194'>195</a>\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/utils.py?line=195'>196</a>\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/utils.py?line=196'>197</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/utils.py?line=197'>198</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'drug_exposure.*' given input columns 'person_id, drug_exposure_start_date, refills, drug_source_value, drug_exposure_end_date, route_concept_id, quantity, lot_number, days_supply, sig, drug_type_concept_id, drug_source_concept_id, provider_id, route_source_value, drug_exposure_id, dose_unit_source_value, drug_exposure_start_datetime, drug_exposure_end_datetime, visit_detail_id, verbatim_end_date, stop_reason, drug_concept_id, visit_occurrence_id, person_id, patient_group, apprx_age, sex, race, ethn, min_covid_dt_2, tot_long_data_days, pre_pre_window_start_dt, pre_window_start_dt, pre_window_end_dt, post_window_start_dt, post_window_end_dt, post_visits_count, tot_post_days, tot_covid_days, op_post_visit_ratio'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def exp(Feature_table_builder, drug_exposure):\n",
    "    d = drug_exposure.alias(\"d\")\n",
    "    f = Feature_table_builder.alias(\"f\")\n",
    "\n",
    "    result = d.join(f, col(\"d.person_id\") == col(\"f.person_id\"), \"inner\") \\\n",
    "            .select(\"d.*\")\n",
    "    return(result)\n",
    "\n",
    "Drugs_for_These_Patients = exp(Feature_Table_Builder_v0, drug_exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    drugRollUp = b.sql_statement_04()\n",
    "\n",
    "    covid_drugs = b.sql_statement_02()\n",
    "    pre_pre_drugs = b.sql_statement_10()\n",
    "    pre_drugs = b.sql_statement_07()\n",
    "    post_drugs = b.sql_statement_05()\n",
    "\n",
    "    covidtbl = b.sql_statement_03()\n",
    "    prepretbl = b.sql_statement_11()\n",
    "    pretbl = b.sql_statement_12()\n",
    "    posttbl = b.sql_statement_06()\n",
    "\n",
    "    pre_post_med_count = b.sql_statement_08()\n",
    "\n",
    "    pre_post_med_count_clean = b.sql_statement_09()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
