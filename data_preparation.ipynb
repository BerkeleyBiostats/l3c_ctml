{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seraphinashi/Desktop/l3c_ctml'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify we're in the correct working directory\n",
    "import os\n",
    "os.getcwd()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.STEP1_feature import a_cohort as a\n",
    "from src.STEP1_feature import b_medication as b\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data/training/observation_period.csv\n",
      "synthetic_data/training/drug_exposure.csv\n",
      "synthetic_data/training/death.csv\n",
      "synthetic_data/training/concept.csv\n",
      "synthetic_data/training/measurement.csv\n",
      "synthetic_data/training/condition_occurrence.csv\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"l3c_ctml\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Read CSV file into table\n",
    "data_path = \"synthetic_data/training\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('table', StringType(), True),\n",
    "    StructField('field', StringType(), True),\n",
    "    StructField('type', StringType(), True)\n",
    "])\n",
    "\n",
    "all_fields = spark.createDataFrame([], schema)\n",
    "    \n",
    "for path, subdirs, files in os.walk(data_path):\n",
    "    for name in files:\n",
    "        if \"csv\" in name and name[0]!=\".\":\n",
    "            # table_fields = [(table_name, f.name, str(f.dataType)) for f in datafile.schema.fields]\n",
    "            full_file = (os.path.join(path, name))\n",
    "            df = spark.read.csv(os.path.join(path, name), header=True, inferSchema=True)\n",
    "            var_name = name[:-4]\n",
    "            print(full_file)\n",
    "            globals()[var_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1_cohort_and_features\n",
    "\n",
    "covid_pasc_index_dates = a.sql_statement_01(long_covid_silver_standard)\n",
    "cohort = a.sql_statement_00(covid_pasc_index_dates, person)\n",
    "long_covid_patients = a.sql_statement_08(covid_pasc_index_dates)\n",
    "\n",
    "hosp_cases = a.sql_statement_04(cohort, condition_occurrence, microvisits_to_macrovisits)\n",
    "\n",
    "hosp_and_non = a.sql_statement_06(cohort, hosp_cases)\n",
    "\n",
    "Feature_Table_Builder_v0 = a.sql_statement_03(covid_pasc_index_dates, hosp_and_non, microvisits_to_macrovisits)\n",
    "icu_visits = a.sql_statement_05(microvisits_to_macrovisits, concept) # empty for some reason\n",
    "inpatient_visits = a.sql_statement_07(microvisits_to_macrovisits, concept)\n",
    "\n",
    "tot_icu_days_calc = a.sql_statement_09(Feature_Table_Builder_v0, icu_visits)\n",
    "tot_ip_days_calc = a.sql_statement_10(Feature_Table_Builder_v0, inpatient_visits)\n",
    "\n",
    "Feature_Table_Builder = a.sql_statement_02(Feature_Table_Builder_v0, tot_icu_days_calc, tot_ip_days_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2_med_feature_table\n",
    "DrugConcepts = b.sql_statement_00(concept)\n",
    "Drugs_for_These_Patients = b.sql_statement_01(Feature_Table_Builder, drug_exposure)\n",
    "\n",
    "drugRollUp = b.sql_statement_04(DrugConcepts, Drugs_for_These_Patients)\n",
    "\n",
    "covid_drugs = b.sql_statement_02(Feature_Table_Builder, drugRollUp)\n",
    "pre_pre_drugs = b.sql_statement_10(Feature_Table_Builder, drugRollUp)\n",
    "pre_drugs = b.sql_statement_07(Feature_Table_Builder, drugRollUp)\n",
    "post_drugs = b.sql_statement_05(Feature_Table_Builder, drugRollUp)\n",
    "\n",
    "covidtbl = b.sql_statement_03(Feature_Table_Builder, covid_drugs, microvisits_to_macrovisits)\n",
    "prepretbl = b.sql_statement_11(Feature_Table_Builder, covid_drugs, microvisits_to_macrovisits)\n",
    "pretbl = b.sql_statement_12(Feature_Table_Builder, pre_pre_drugs, microvisits_to_macrovisits)\n",
    "posttbl = b.sql_statement_06(Feature_Table_Builder, post_drugs, microvisits_to_macrovisits)\n",
    "\n",
    "pre_post_med_count = b.sql_statement_08(covidtbl, posttbl, prepretbl, pretbl)\n",
    "\n",
    "pre_post_med_count_clean = b.sql_statement_09(Feature_Table_Builder, pre_post_med_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
