{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seraphinashi/Desktop/l3c_ctml'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify we're in the correct working directory\n",
    "import os\n",
    "os.getcwd()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.STEP1_feature import a_cohort as a\n",
    "from src.STEP1_feature import b_medication as b\n",
    "from src.STEP1_feature import c_diagnosis as c\n",
    "from src.STEP1_feature import d_lab_measures as d\n",
    "from src.STEP1_feature import e_comorbidity as e\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data/training/observation_period.csv\n",
      "synthetic_data/training/drug_exposure.csv\n",
      "synthetic_data/training/death.csv\n",
      "synthetic_data/training/concept.csv\n",
      "synthetic_data/training/measurement.csv\n",
      "synthetic_data/training/condition_occurrence.csv\n",
      "synthetic_data/training/microvisits_to_macrovisits.csv\n",
      "synthetic_data/training/visit_occurrence.csv\n",
      "synthetic_data/training/long_covid_silver_standard.csv\n",
      "synthetic_data/training/person.csv\n",
      "synthetic_data/training/observation.csv\n",
      "synthetic_data/training/procedure_occurrence.csv\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"l3c_ctml\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Read CSV file into table\n",
    "data_path = \"synthetic_data/training\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('table', StringType(), True),\n",
    "    StructField('field', StringType(), True),\n",
    "    StructField('type', StringType(), True)\n",
    "])\n",
    "\n",
    "all_fields = spark.createDataFrame([], schema)\n",
    "    \n",
    "for path, subdirs, files in os.walk(data_path):\n",
    "    for name in files:\n",
    "        if \"csv\" in name and name[0]!=\".\":\n",
    "            # table_fields = [(table_name, f.name, str(f.dataType)) for f in datafile.schema.fields]\n",
    "            full_file = (os.path.join(path, name))\n",
    "            df = spark.read.csv(os.path.join(path, name), header=True, inferSchema=True)\n",
    "            var_name = name[:-4]\n",
    "            print(full_file)\n",
    "            globals()[var_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1_cohort_and_features\n",
    "\n",
    "covid_pasc_index_dates = a.sql_statement_01(long_covid_silver_standard)\n",
    "cohort = a.sql_statement_00(covid_pasc_index_dates, person)\n",
    "long_covid_patients = a.sql_statement_08(covid_pasc_index_dates)\n",
    "\n",
    "hosp_cases = a.sql_statement_04(cohort, condition_occurrence, microvisits_to_macrovisits)\n",
    "\n",
    "hosp_and_non = a.sql_statement_06(cohort, hosp_cases)\n",
    "\n",
    "Feature_Table_Builder_v0 = a.sql_statement_03(covid_pasc_index_dates, hosp_and_non, microvisits_to_macrovisits)\n",
    "icu_visits = a.sql_statement_05(microvisits_to_macrovisits, concept) # empty for some reason\n",
    "inpatient_visits = a.sql_statement_07(microvisits_to_macrovisits, concept)\n",
    "\n",
    "tot_icu_days_calc = a.sql_statement_09(Feature_Table_Builder_v0, icu_visits)\n",
    "tot_ip_days_calc = a.sql_statement_10(Feature_Table_Builder_v0, inpatient_visits)\n",
    "\n",
    "Feature_Table_Builder = a.sql_statement_02(Feature_Table_Builder_v0, tot_icu_days_calc, tot_ip_days_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2_med_feature_table\n",
    "DrugConcepts = b.sql_statement_00(concept)\n",
    "Drugs_for_These_Patients = b.sql_statement_01(Feature_Table_Builder, drug_exposure)\n",
    "\n",
    "drugRollUp = b.sql_statement_04(DrugConcepts, Drugs_for_These_Patients)\n",
    "\n",
    "covid_drugs = b.sql_statement_02(Feature_Table_Builder, drugRollUp)\n",
    "pre_pre_drugs = b.sql_statement_10(Feature_Table_Builder, drugRollUp)\n",
    "pre_drugs = b.sql_statement_07(Feature_Table_Builder, drugRollUp)\n",
    "post_drugs = b.sql_statement_05(Feature_Table_Builder, drugRollUp)\n",
    "\n",
    "covidtbl = b.sql_statement_03(Feature_Table_Builder, covid_drugs, microvisits_to_macrovisits)\n",
    "prepretbl = b.sql_statement_11(Feature_Table_Builder, covid_drugs, microvisits_to_macrovisits)\n",
    "pretbl = b.sql_statement_12(Feature_Table_Builder, pre_pre_drugs, microvisits_to_macrovisits)\n",
    "posttbl = b.sql_statement_06(Feature_Table_Builder, post_drugs, microvisits_to_macrovisits)\n",
    "\n",
    "pre_post_med_count = b.sql_statement_08(covidtbl, posttbl, prepretbl, pretbl)\n",
    "\n",
    "pre_post_med_count_clean = b.sql_statement_09(Feature_Table_Builder, pre_post_med_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3_dx_feature_table\n",
    "pre_pre_condition = c.sql_statement_05(Feature_Table_Builder, condition_occurrence)\n",
    "pre_condition = c.sql_statement_03(Feature_Table_Builder, condition_occurrence)\n",
    "covid_condition = c.sql_statement_00(Feature_Table_Builder, condition_occurrence)\n",
    "post_condition = c.sql_statement_02(Feature_Table_Builder, condition_occurrence)\n",
    "\n",
    "four_windows_dx_counts = c.sql_statement_01(Feature_Table_Builder, microvisits_to_macrovisits, pre_pre_condition, pre_condition, covid_condition, post_condition)\n",
    "\n",
    "pre_post_dx_count_clean = c.sql_statement_04(Feature_Table_Builder, four_windows_dx_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4_lab_measure_table\n",
    "measure_person = d.measurement_person(measurement, Feature_Table_Builder, concept)\n",
    "pre_pre_measurement = d.sql_statement_05(Feature_Table_Builder, measure_person )\n",
    "\n",
    "pre_measurement = d.sql_statement_04( Feature_Table_Builder, measure_person )\n",
    "covid_measurement = d.sql_statement_00(Feature_Table_Builder, measure_person )\n",
    "post_measurement = d.sql_statement_03(Feature_Table_Builder, measure_person )\n",
    "\n",
    "four_windows_measure = d.sql_statement_01(covid_measurement, post_measurement, pre_measurement, pre_pre_measurement)\n",
    "\n",
    "lab_measures_clean = d.sql_statement_02(four_windows_measure)\n",
    "\n",
    "# 5_comorbidity_table\n",
    "high_level_condition_occur = e.sql_statement_01(Feature_Table_Builder, condition_occurrence, concept)\n",
    "\n",
    "comorbidity_counts = e.sql_statement_00(Feature_Table_Builder, high_level_condition_occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.context import SparkContext\n",
    "ctx = SparkContext.getOrCreate()\n",
    "\n",
    "# Read in the file containing the list of model features, one per line\n",
    "# returns cols_for_model, which is used in several other functions\n",
    "def read_model_columns():\n",
    "\n",
    "    f = open('feature_list.txt', 'r')\n",
    "    lines = f.readlines()\n",
    "    cols_for_model = [l.strip() for l in lines]\n",
    "    f.close()\n",
    "    return cols_for_model\n",
    "\n",
    "def pivot_covid(df):\n",
    "    # make the column name standard\n",
    "    df = df.withColumn(\"measure_type\", F.lower(F.regexp_replace(df[\"measure_type\"], \"[^A-Za-z_0-9]\", \"_\" )))\n",
    "    df = df.groupby(\"person_id\").pivot(\"measure_type\").agg(\n",
    "        F.max(\"c_any_measure\").alias(\"measure_covid_ind\"),\n",
    "        F.max(\"c_any_pos\").alias(\"positive_covid_ind\"),\n",
    "        F.max(\"c_covid_length\").alias(\"covid_length_covid\"),\n",
    "        F.max(\"c_impute_covid_length\").alias(\"impute_covid_ind\"),\n",
    "        F.max(\"post_any_measure\").alias(\"measure_post_ind\"),\n",
    "        F.max(\"post_any_pos\").alias(\"positive_post_ind\"),\n",
    "        F.max(\"post_covid_length\").alias(\"covid_length_post\"),\n",
    "        F.max(\"post_impute_covid_length\").alias(\"impute_post_ind\"))\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pivot_dx(dx_df, cols_for_model):\n",
    "\n",
    "    # Filter only to dx used in model and then pivot\n",
    "    # This greatly improves performance as both spark and pandas do poorly with very wide datasets\n",
    "\n",
    "    dx_df = dx_df.filter(dx_df[\"high_level_condition\"].isin(cols_for_model))    \n",
    "    dx_df = dx_df.groupby(\"person_id\").pivot(\"high_level_condition\").agg(\n",
    "        F.max(\"pre_dx_count_sum\").alias(\"pre_dx\"),\n",
    "        F.max(\"pre_pre_dx_count_sum\").alias(\"pp_dx\"),\n",
    "        F.max(\"covid_dx_count_sum\").alias(\"c_dx\"),\n",
    "        F.max(\"post_dx_count_sum\").alias(\"post_dx\"))\n",
    "    \n",
    "    # the absence of a diagnosis record means it is neither greater in post or only in post\n",
    "    dx_df = dx_df.fillna(0)\n",
    "\n",
    "    return dx_df\n",
    "\n",
    "\n",
    "def pivot_meds(med_df, cols_for_model):\n",
    "    \n",
    "    # Filter only to meds used in the canonical all patients model and then pivot\n",
    "    # This greatly improves performance as both spark and pandas do poorly with very wide datasets\n",
    "    \n",
    "    med_df = med_df.filter(med_df[\"ingredient\"].isin(cols_for_model))    \n",
    "    # med_df = med_df.groupby(\"person_id\").pivot(\"ingredient\").agg(F.max(\"post_only_med\").alias(\"post_only_med\"))\n",
    "    med_df = med_df.groupby(\"person_id\").pivot(\"ingredient\").agg(\n",
    "        F.max(\"pre_med_count\").alias(\"pre_med\"),\n",
    "        F.max(\"pre_pre_med_count\").alias(\"pp_med\"),\n",
    "        F.max(\"covid_med_count\").alias(\"covid_med\"),\n",
    "        F.max(\"post_med_count\").alias(\"post_med\"))\n",
    "    \n",
    "    \n",
    "    # if there is no row for a patient:drug combination, there will be nulls in the pivot.  This is converted to 0 to represent the absence of a drug exposure.\n",
    "    med_df = med_df.fillna(0)\n",
    "\n",
    "    return med_df\n",
    "\n",
    "def pivot_measure(measure_df):\n",
    "    \n",
    "    # Filter only to measures used in the canonical all patients model and then pivot\n",
    "    # This greatly improves performance as both spark and pandas do poorly with very wide datasets\n",
    "    measure_df = measure_df.drop('measurement_concept_id')\n",
    "    measure_df = measure_df.withColumn(\"measurement_concept_name\", F.lower(F.regexp_replace(measure_df[\"measurement_concept_name\"], \"[^A-Za-z_0-9]\", \"_\" )))\n",
    "    \n",
    "    measure_df = measure_df.groupby(\"person_id\").pivot(\"measurement_concept_name\").agg(\n",
    "        F.max(\"pre_pre_max\").alias(\"pp_max\"),\n",
    "        F.max(\"pre_pre_min\").alias(\"pp_min\"),\n",
    "        F.max(\"pre_pre_avg\").alias(\"pp_avg\"),\n",
    "        F.max(\"pre_max\").alias(\"pre_max\"),\n",
    "        F.max(\"pre_min\").alias(\"pre_pre_min\"),\n",
    "        F.max(\"pre_avg\").alias(\"pre_avg\"),\n",
    "        F.max(\"covid_max\").alias(\"covid_max\"),\n",
    "        F.max(\"covid_min\").alias(\"covid_min\"),\n",
    "        F.max(\"covid_avg\").alias(\"covid_avg\"),\n",
    "\n",
    "        F.max(\"post_max\").alias(\"post_max\"),\n",
    "        F.max(\"post_min\").alias(\"post_min\"),\n",
    "        F.max(\"post_avg\").alias(\"post_avg\"))\n",
    "    \n",
    "    # if there is no row for a patient:drug combination, there will be nulls in the pivot.  This is converted to 0 to represent the absence of a measurement.\n",
    "    # measure_df = measure_df.fillna('NA')\n",
    "\n",
    "    return measure_df\n",
    "\n",
    "\n",
    "def pivot_nlp(nlp_df):\n",
    "    nlp_df = nlp_df.withColumn(\"note_nlp_concept_name\", F.lower(F.regexp_replace(nlp_df[\"note_nlp_concept_name\"], \"[^A-Za-z_0-9]\", \"_\" )))\n",
    "    nlp_df = nlp_df.groupby(\"person_id\").pivot(\"note_nlp_concept_name\").agg(\n",
    "        F.max(\"pre_nlp_count\").alias(\"pre_nlp\"),\n",
    "        F.max(\"pre_pre_nlp_count\").alias(\"pp_nlp\"),\n",
    "        F.max(\"covid_nlp_count\").alias(\"covid_nlp\"),\n",
    "        F.max(\"post_nlp_count\").alias(\"post_nlp\"))\n",
    "        \n",
    "    nlp_df = nlp_df.fillna(0)\n",
    "\n",
    "    return nlp_df\n",
    "\n",
    "def pivot_device(device_df):\n",
    "    device_df = device_df.withColumn(\"device_concept_name\", F.lower(F.regexp_replace(device_df[\"device_concept_name\"], \"[^A-Za-z_0-9]\", \"_\" )))\n",
    "    device_df = device_df.groupby(\"person_id\").pivot(\"device_concept_name\").agg(\n",
    "        F.max(\"pre_device_count\").alias(\"pre_device\"),\n",
    "        F.max(\"pre_pre_device_count\").alias(\"pp_device\"),\n",
    "        F.max(\"covid_device_count\").alias(\"covid_device\"),\n",
    "        F.max(\"post_device_count\").alias(\"post_device\"))\n",
    "        \n",
    "    device_df = device_df.fillna(0)\n",
    "\n",
    "    return device_df\n",
    "\n",
    "def build_final_feature_table(med_df, dx_df, add_labels, count_dx_pre_and_post, measure_df, covid_df, device_df):\n",
    "\n",
    "    count_dx = count_dx_pre_and_post\n",
    "\n",
    "    df = add_labels.join(med_df, on=\"person_id\",  how=\"left\")\n",
    "    df = df.join(dx_df, on='person_id', how='left')\n",
    "    df = df.join(count_dx, on='person_id', how='left')\n",
    "    # Some patients in the condition data aren't in the drug dataset\n",
    "    # meaning they don't have any drugs in the relevant period \n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df = df.join(measure_df, on='person_id', how='left')\n",
    "    df = df.fillna(-999)\n",
    "\n",
    "    convert_ind =  udf(lambda old_c: 1 if old_c ==-999 else 0, IntegerType())\n",
    "\n",
    "    # create new indicator columns and join them with the df\n",
    "    ind_df = df.select([convert_ind(df[col_name]).alias(col_name+'_ind') if col_name != 'person_id' else df[col_name] for col_name in measure_df.columns])\n",
    "    ind_df = ind_df.withColumnRenamed('person_id_ind', 'person_id')\n",
    "    df = df.join(ind_df, on='person_id', how='left')\n",
    "\n",
    "    df = df.na.replace(-999, 0)\n",
    "\n",
    "    # left join with covid measures\n",
    "\n",
    "    df = df.join(covid_df, on='person_id', how='left')\n",
    "    # df = df.join(nlp_df, on='person_id', how='left')\n",
    "    df = df.join(device_df, on='person_id', how='left')\n",
    "    df = df.fillna(0)\n",
    "    result = df\n",
    "    \n",
    "    drop_cols = []\n",
    "    cols = result.columns\n",
    "    for c in cols:\n",
    "\n",
    "        # drop ALL the race and ethnicity columns\n",
    "        # if re.match('^race_', c) or re.match('^ethn', c):\n",
    "            # drop_cols.append(c)\n",
    "\n",
    "        # Among the sex columns, keep only male and unknown\n",
    "        if re.match('^sex_', c) and c != 'sex_male' and c != 'sex_unknown':\n",
    "            drop_cols.append(c)\n",
    "\n",
    "        # Among the ethn columns, keep only hispanic_or_latino and unknown\n",
    "        if re.match('^ethn_', c) and c != 'ethn_hispanic_or_latino' and c != 'ethn_unknown':\n",
    "            drop_cols.append(c)\n",
    "\n",
    "\n",
    "    # # drop the 'no' versions of disease history, keeping the 'yes' versions\n",
    "    # # drop disorder by body site - too vague\n",
    "    drop_cols.extend([\"diabetes_ind_no\", \"kidney_ind_no\", \"chf_ind_no\", \"chronicpulm_ind_no\", \"patient_group\", \"disorder_by_body_site\"])\n",
    "\n",
    "    result = result.drop(*drop_cols)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pre_post_dx_count_clean.alias('pp')\n",
    "ct = concept.alias('ct')\n",
    "lc = long_covid_patients.alias('lc')\n",
    "\n",
    "df = pp.join(lc, on='person_id', how='inner')\n",
    "df = df.join(ct, on=[df.condition_concept_id  == ct.concept_id], how='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_rollup(long_covid_patients, pre_post_dx_count_clean, concept):\n",
    "   \n",
    "    pp = pre_post_dx_count_clean.alias('pp')\n",
    "    ct = concept.alias('ct')\n",
    "    lc = long_covid_patients.alias('lc')\n",
    "\n",
    "    df = pp.join(lc, on='person_id', how='inner')\n",
    "    df = df.join(ct, on=[df.condition_concept_id  == ct.concept_id], how='inner')\n",
    "\n",
    "    df = df.filter( ~df['concept_name'].isin(\n",
    "                                                ['General problem AND/OR complaint',\n",
    "                                                'Disease',\n",
    "                                                'Sequelae of disorders classified by disorder-system',\n",
    "                                                'Sequela of disorder',\n",
    "                                                'Sequela',\n",
    "                                                'Recurrent disease',\n",
    "                                                'Problem',\n",
    "                                                'Acute disease',\n",
    "                                                'Chronic disease',\n",
    "                                                'Complication'\n",
    "                                                ]))\n",
    "    \n",
    "    generic_codes = ['finding', 'disorder of', 'by site', 'right', 'left']\n",
    "\n",
    "    for gc in generic_codes:\n",
    "        df = df.filter( ~F.lower(ct.concept_name).like('%' + gc + '%') )\n",
    "        \n",
    "        if gc not in ['right', 'left']:\n",
    "            df = df.filter( ~F.lower(pp.condition_concept_name).like('%' + gc + '%') )\n",
    "\n",
    "    df = df.filter(ca.min_levels_of_separation.between(0,2))\n",
    "\n",
    "\n",
    "    \n",
    "    df = df.groupby(['ct.concept_name', 'pp.condition_concept_name', 'pp.condition_concept_id', \n",
    "                    'ca.min_levels_of_separation', 'ca.max_levels_of_separation']).agg(F.countDistinct('pp.person_id').alias('ptct_training'))\n",
    "\n",
    "    df = df.withColumnRenamed('concept_name', 'parent_concept_name')\n",
    "    df = df.withColumnRenamed('condition_concept_name', 'child_concept_name')\n",
    "    df = df.withColumnRenamed('min_levels_of_separation', 'min_hops_bt_parent_child')\n",
    "    df = df.withColumnRenamed('max_levels_of_separation', 'max_hops_bt_parent_child')\n",
    "    df = df.withColumnRenamed('condition_concept_id', 'child_concept_id')\n",
    "\n",
    "    return df\n",
    "\n",
    "condition_rollup = condition_rollup(long_covid_patients, pre_post_dx_count_clean, concept)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
